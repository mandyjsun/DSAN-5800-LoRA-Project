{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1eaa916",
   "metadata": {},
   "source": [
    "# MBPP Evaluation Analysis\n",
    "\n",
    "This notebook summarizes results from baseline and LoRA r=8 runs using saved metrics, without loading any models. It compares pass@1 and syntax rates and shows representative examples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6aa53d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, ast\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# Paths\n",
    "BASELINE_RESULTS = \"artifacts/metrics/baseline_mbpp_results.json\"  # may be missing\n",
    "BASELINE_GENERATIONS = \"artifacts/metrics/baseline_generations.jsonl\"\n",
    "MBPP_TEST = \"data/processed/mbpp_test.jsonl\"\n",
    "R8_RESULTS = \"artifacts/metrics/mistral7b-code-r8-mbpp_results.json\"\n",
    "\n",
    "\n",
    "def load_jsonl(path: str) -> List[Dict]:\n",
    "    items: List[Dict] = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            items.append(json.loads(line))\n",
    "    return items\n",
    "\n",
    "\n",
    "def safe_syntax_ok(code: str) -> bool:\n",
    "    try:\n",
    "        ast.parse(code)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def run_tests_on_code(code: str, tests: List[str]) -> Tuple[bool, List[str]]:\n",
    "    # WARNING: executes code/tests; use only in trusted environments\n",
    "    g: Dict = {}\n",
    "    try:\n",
    "        exec(code, g, g)  # noqa: S102\n",
    "    except Exception as e:\n",
    "        return False, [f\"Execution error: {type(e).__name__}: {e}\"]\n",
    "    errors: List[str] = []\n",
    "    for t in tests:\n",
    "        try:\n",
    "            exec(t, g, g)  # noqa: S102\n",
    "        except Exception as e:\n",
    "            errors.append(f\"Test failed: {t} -> {type(e).__name__}: {e}\")\n",
    "    return (len(errors) == 0), errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "285ff56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA r=8 summary: {'total': 500, 'syntax_ok': 496, 'syntax_rate': 0.992, 'pass': 22, 'pass_rate': 0.044, 'model': 'mistralai/Mistral-7B-Instruct-v0.2', 'lora_dir': 'artifacts/checkpoints/mistral7b-code-r8'}\n"
     ]
    }
   ],
   "source": [
    "# Load r=8 results\n",
    "r8 = json.load(open(R8_RESULTS, \"r\", encoding=\"utf-8\")) if os.path.exists(R8_RESULTS) else None\n",
    "if r8:\n",
    "    print(\"LoRA r=8 summary:\", r8[\"summary\"])  # contains total, syntax_rate, pass_rate\n",
    "else:\n",
    "    print(\"LoRA r=8 results not found at:\", R8_RESULTS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df27fcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline summary (from results): {'total': 500, 'syntax_ok': 486, 'syntax_rate': 0.972, 'pass': 11, 'pass_rate': 0.022, 'model': 'mistralai/Mistral-7B-Instruct-v0.2', 'lora_dir': None}\n"
     ]
    }
   ],
   "source": [
    "# Load or compute baseline metrics\n",
    "baseline = None\n",
    "if os.path.exists(BASELINE_RESULTS):\n",
    "    try:\n",
    "        baseline = json.load(open(BASELINE_RESULTS, \"r\", encoding=\"utf-8\"))\n",
    "        print(\"Baseline summary (from results):\", baseline[\"summary\"])\n",
    "    except Exception as e:\n",
    "        print(\"Could not read baseline results:\", e)\n",
    "\n",
    "if baseline is None and os.path.exists(BASELINE_GENERATIONS) and os.path.exists(MBPP_TEST):\n",
    "    print(\"Baseline summary not found; computing from generations + MBPP tests (this may take a while)...\")\n",
    "    gens = load_jsonl(BASELINE_GENERATIONS)\n",
    "    tests = {ex.get(\"task_id\"): (ex.get(\"tests\") or []) for ex in load_jsonl(MBPP_TEST)}\n",
    "    total = len(gens)\n",
    "    num_syntax_ok = 0\n",
    "    num_pass = 0\n",
    "    for idx, g in enumerate(gens, start=1):\n",
    "        code = g.get(\"generated\", \"\").strip()\n",
    "        ok = safe_syntax_ok(code)\n",
    "        if ok:\n",
    "            num_syntax_ok += 1\n",
    "        task_id = g.get(\"task_id\")\n",
    "        tlist = tests.get(task_id, [])\n",
    "        passed = False\n",
    "        if tlist:\n",
    "            p, _ = run_tests_on_code(code, tlist)\n",
    "            passed = p\n",
    "        if passed:\n",
    "            num_pass += 1\n",
    "        if idx % 50 == 0 or idx == total:\n",
    "            print(f\"[baseline] processed {idx}/{total}\")\n",
    "    baseline_summary = {\n",
    "        \"total\": total,\n",
    "        \"syntax_ok\": num_syntax_ok,\n",
    "        \"syntax_rate\": num_syntax_ok / max(1, total),\n",
    "        \"pass\": num_pass,\n",
    "        \"pass_rate\": num_pass / max(1, total),\n",
    "        \"model\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "        \"lora_dir\": None,\n",
    "    }\n",
    "    print(\"Baseline summary (computed):\", baseline_summary)\n",
    "else:\n",
    "    if baseline is None:\n",
    "        print(\"Baseline generations or MBPP tests not found; skipping baseline computation.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12cafb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline pass_rate: 0.022 syntax_rate: 0.972\n",
      "LoRA r=8 pass_rate: 0.044 syntax_rate: 0.992\n"
     ]
    }
   ],
   "source": [
    "# Comparison\n",
    "r8_summary = r8[\"summary\"] if r8 else None\n",
    "baseline_summary = baseline[\"summary\"] if isinstance(baseline, dict) and \"summary\" in baseline else (\n",
    "    locals().get(\"baseline_summary\") if \"baseline_summary\" in locals() else None\n",
    ")\n",
    "\n",
    "if r8_summary and baseline_summary:\n",
    "    print(\"Baseline pass_rate:\", round(baseline_summary[\"pass_rate\"], 3), \"syntax_rate:\", round(baseline_summary[\"syntax_rate\"], 3))\n",
    "    print(\"LoRA r=8 pass_rate:\", round(r8_summary[\"pass_rate\"], 3), \"syntax_rate:\", round(r8_summary[\"syntax_rate\"], 3))\n",
    "else:\n",
    "    print(\"Not enough data to compare both baselines and r=8.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6729d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples — Passed:\n",
      "- task 54 | Write a function to sort the given array by using counting sort.\n",
      "def counting_sort(arr): ...\n",
      "\n",
      "- task 71 | Write a function to sort a list of elements using comb sort.\n",
      "def comb_sort(arr): ...\n",
      "\n",
      "- task 80 | Write a function to find the nth tetrahedral number.\n",
      "def tetrahedral_number(n): ...\n",
      "\n",
      "Examples — Failed:\n",
      "- task 11 | Write a python function to remove first and last occurrence of a given character\n",
      "Error: Test failed: assert remove_Occ(\"hello\",\"l\") == \"heo\" -> NameError: name 'remove_Occ' is not defined\n",
      "- task 12 | Write a function to sort a given matrix in ascending order according to the sum \n",
      "Error: Test failed: assert sort_matrix([[1, 2, 3], [2, 4, 5], [1, 1, 1]])==[[1, 1, 1], [1, 2, 3], [2, 4, 5]] -> AssertionError: \n",
      "- task 13 | Write a function to count the most common words in a dictionary.\n",
      "Error: Test failed: assert count_common(['red','green','black','pink','black','white','black','eyes','white','black','orange','pink','pink','red','red','white','orange','white',\"black\",'pink','green','green','pink','green','pink','white','orange',\"orange\",'red']) == [('pink', 6), ('black', 5), ('white', 5), ('red', 4)] -> NameError: name 'count_common' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Sample successes and failures from r=8\n",
    "if r8 and \"results\" in r8:\n",
    "    results = r8[\"results\"]\n",
    "    passed = [r for r in results if r.get(\"passed\")]\n",
    "    failed = [r for r in results if not r.get(\"passed\")]\n",
    "    print(\"Examples — Passed:\")\n",
    "    for ex in passed[:3]:\n",
    "        print(\"- task\", ex.get(\"task_id\"), \"|\", ex.get(\"instruction\")[:80])\n",
    "        print((ex.get(\"generated\") or \"\").split(\"\\n\")[0][:120], \"...\\n\")\n",
    "    print(\"Examples — Failed:\")\n",
    "    for ex in failed[:3]:\n",
    "        print(\"- task\", ex.get(\"task_id\"), \"|\", ex.get(\"instruction\")[:80])\n",
    "        errs = ex.get(\"errors\") or []\n",
    "        print(\"Error:\", errs[0] if errs else \"(no details)\")\n",
    "else:\n",
    "    print(\"r=8 results not found or missing 'results' field.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad5a21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
